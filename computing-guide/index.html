<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Comprehensive guide for using the Euler HPC cluster at ETH Zurich - Robotics Systems Lab"><meta name=author content="Robotics Systems Lab, ETH Zurich"><link href=https://leggedrobotics.github.io/euler-cluster-guide/computing-guide/ rel=canonical><link href=../python-environments/ rel=prev><link href=../container-workflow/ rel=next><link rel=icon href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.21"><title>Overview - RSL Euler Cluster Guide</title><link rel=stylesheet href=../assets/stylesheets/main.2a3383ac.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#computing-on-euler class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="RSL Euler Cluster Guide" class="md-header__button md-logo" aria-label="RSL Euler Cluster Guide" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> RSL Euler Cluster Guide </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Overview </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/leggedrobotics/euler-cluster-guide title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> leggedrobotics/euler-cluster-guide </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../getting-started/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../data-management/ class=md-tabs__link> Data Management </a> </li> <li class=md-tabs__item> <a href=../python-environments/ class=md-tabs__link> Python & ML </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> Computing </a> </li> <li class=md-tabs__item> <a href=../container-workflow/ class=md-tabs__link> Container Workflow </a> </li> <li class=md-tabs__item> <a href=../complete-guide/ class=md-tabs__link> Complete Guide </a> </li> <li class=md-tabs__item> <a href=../scripts/ class=md-tabs__link> Scripts Library </a> </li> <li class=md-tabs__item> <a href=../troubleshooting/ class=md-tabs__link> Troubleshooting </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="RSL Euler Cluster Guide" class="md-nav__button md-logo" aria-label="RSL Euler Cluster Guide" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> RSL Euler Cluster Guide </label> <div class=md-nav__source> <a href=https://github.com/leggedrobotics/euler-cluster-guide title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> leggedrobotics/euler-cluster-guide </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../getting-started/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../getting-started.md#access-requirements class=md-nav__link> <span class=md-ellipsis> Access Requirements </span> </a> </li> <li class=md-nav__item> <a href=../getting-started.md#connecting-to-euler-via-ssh class=md-nav__link> <span class=md-ellipsis> SSH Setup </span> </a> </li> <li class=md-nav__item> <a href=../getting-started.md#verifying-access-to-the-rsl-shareholder-group class=md-nav__link> <span class=md-ellipsis> Verify Access </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../data-management/ class=md-nav__link> <span class=md-ellipsis> Data Management </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Python & ML </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Python & ML </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../python-environments/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../python-environments.md#setting-up-miniconda class=md-nav__link> <span class=md-ellipsis> Miniconda Setup </span> </a> </li> <li class=md-nav__item> <a href=../python-environments.md#ml-training-workflow class=md-nav__link> <span class=md-ellipsis> ML Training </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Computing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Computing </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Overview </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Overview </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#table-of-contents class=md-nav__link> <span class=md-ellipsis> Table of Contents </span> </a> </li> <li class=md-nav__item> <a href=#interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸ–¥ï¸ Interactive Sessions </span> </a> <nav class=md-nav aria-label="ğŸ–¥ï¸ Interactive Sessions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸš€ Requesting Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#common-interactive-session-configurations class=md-nav__link> <span class=md-ellipsis> ğŸ“Š Common Interactive Session Configurations </span> </a> <nav class=md-nav aria-label="ğŸ“Š Common Interactive Session Configurations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-cpu-session class=md-nav__link> <span class=md-ellipsis> Basic CPU Session </span> </a> </li> <li class=md-nav__item> <a href=#gpu-development-session class=md-nav__link> <span class=md-ellipsis> GPU Development Session </span> </a> </li> <li class=md-nav__item> <a href=#multi-gpu-session class=md-nav__link> <span class=md-ellipsis> Multi-GPU Session </span> </a> </li> <li class=md-nav__item> <a href=#high-memory-session class=md-nav__link> <span class=md-ellipsis> High Memory Session </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#working-in-interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸ”§ Working in Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#interactive-development-workflow class=md-nav__link> <span class=md-ellipsis> ğŸ“ Interactive Development Workflow </span> </a> <nav class=md-nav aria-label="ğŸ“ Interactive Development Workflow"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-code-development-with-gpu class=md-nav__link> <span class=md-ellipsis> 1. Code Development with GPU </span> </a> </li> <li class=md-nav__item> <a href=#2-interactive-pythonipython class=md-nav__link> <span class=md-ellipsis> 2. Interactive Python/IPython </span> </a> </li> <li class=md-nav__item> <a href=#3-container-development class=md-nav__link> <span class=md-ellipsis> 3. Container Development </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-jupyter-sessions class=md-nav__link> <span class=md-ellipsis> ğŸŒ Interactive Jupyter Sessions </span> </a> <nav class=md-nav aria-label="ğŸŒ Interactive Jupyter Sessions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#launching-jupyter-from-command-line class=md-nav__link> <span class=md-ellipsis> Launching Jupyter from Command Line </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#vscode-remote-development class=md-nav__link> <span class=md-ellipsis> ğŸ’» VSCode Remote Development </span> </a> <nav class=md-nav aria-label="ğŸ’» VSCode Remote Development"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-via-jupyterhub class=md-nav__link> <span class=md-ellipsis> Option 1: Via JupyterHub </span> </a> </li> <li class=md-nav__item> <a href=#option-2-ssh-remote-development class=md-nav__link> <span class=md-ellipsis> Option 2: SSH Remote Development </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#time-limits-and-best-practices class=md-nav__link> <span class=md-ellipsis> â° Time Limits and Best Practices </span> </a> <nav class=md-nav aria-label="â° Time Limits and Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#time-limits class=md-nav__link> <span class=md-ellipsis> Time Limits </span> </a> </li> <li class=md-nav__item> <a href=#best-practices class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> â— Common Issues and Solutions </span> </a> </li> <li class=md-nav__item> <a href=#quick-reference-card class=md-nav__link> <span class=md-ellipsis> ğŸ“‹ Quick Reference Card </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#batch-jobs-with-slurm class=md-nav__link> <span class=md-ellipsis> ğŸ“ Batch Jobs with SLURM </span> </a> <nav class=md-nav aria-label="ğŸ“ Batch Jobs with SLURM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-job-script-template class=md-nav__link> <span class=md-ellipsis> ğŸ¯ Basic Job Script Template </span> </a> </li> <li class=md-nav__item> <a href=#gpu-selection-and-memory-requirements class=md-nav__link> <span class=md-ellipsis> ğŸ® GPU Selection and Memory Requirements </span> </a> <nav class=md-nav aria-label="ğŸ® GPU Selection and Memory Requirements"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-specific-gpu-types class=md-nav__link> <span class=md-ellipsis> Requesting Specific GPU Types </span> </a> </li> <li class=md-nav__item> <a href=#gpu-memory-vs-system-memory class=md-nav__link> <span class=md-ellipsis> GPU Memory vs System Memory </span> </a> </li> <li class=md-nav__item> <a href=#example-large-model-training class=md-nav__link> <span class=md-ellipsis> Example: Large Model Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gpu-training-script class=md-nav__link> <span class=md-ellipsis> ğŸš€ GPU Training Script </span> </a> </li> <li class=md-nav__item> <a href=#multi-gpu-distributed-training class=md-nav__link> <span class=md-ellipsis> ğŸ”¥ Multi-GPU Distributed Training </span> </a> </li> <li class=md-nav__item> <a href=#array-jobs-for-parallel-processing class=md-nav__link> <span class=md-ellipsis> ğŸ”„ Array Jobs for Parallel Processing </span> </a> </li> <li class=md-nav__item> <a href=#container-based-job class=md-nav__link> <span class=md-ellipsis> ğŸ“¦ Container-Based Job </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#job-monitoring-and-management class=md-nav__link> <span class=md-ellipsis> ğŸ” Job Monitoring and Management </span> </a> <nav class=md-nav aria-label="ğŸ” Job Monitoring and Management"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#useful-slurm-commands class=md-nav__link> <span class=md-ellipsis> Useful SLURM Commands </span> </a> </li> <li class=md-nav__item> <a href=#debugging-failed-jobs class=md-nav__link> <span class=md-ellipsis> ğŸ› ï¸ Debugging Failed Jobs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#best-practices_1 class=md-nav__link> <span class=md-ellipsis> ğŸ’¡ Best Practices </span> </a> <nav class=md-nav aria-label="ğŸ’¡ Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#best-practices-for-job-scripts class=md-nav__link> <span class=md-ellipsis> Best Practices for Job Scripts </span> </a> </li> <li class=md-nav__item> <a href=#job-script-checklist class=md-nav__link> <span class=md-ellipsis> ğŸ“ Job Script Checklist </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#test-scripts class=md-nav__link> <span class=md-ellipsis> ğŸ§ª Test Scripts </span> </a> <nav class=md-nav aria-label="ğŸ§ª Test Scripts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interactive-sessions_1 class=md-nav__link> <span class=md-ellipsis> Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#batch-jobs class=md-nav__link> <span class=md-ellipsis> Batch Jobs </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../computing-guide.md#interactive-sessions class=md-nav__link> <span class=md-ellipsis> Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=../computing-guide.md#batch-jobs-with-slurm class=md-nav__link> <span class=md-ellipsis> Batch Jobs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../container-workflow/ class=md-nav__link> <span class=md-ellipsis> Container Workflow </span> </a> </li> <li class=md-nav__item> <a href=../complete-guide/ class=md-nav__link> <span class=md-ellipsis> Complete Guide </span> </a> </li> <li class=md-nav__item> <a href=../scripts/ class=md-nav__link> <span class=md-ellipsis> Scripts Library </span> </a> </li> <li class=md-nav__item> <a href=../troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#table-of-contents class=md-nav__link> <span class=md-ellipsis> Table of Contents </span> </a> </li> <li class=md-nav__item> <a href=#interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸ–¥ï¸ Interactive Sessions </span> </a> <nav class=md-nav aria-label="ğŸ–¥ï¸ Interactive Sessions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸš€ Requesting Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#common-interactive-session-configurations class=md-nav__link> <span class=md-ellipsis> ğŸ“Š Common Interactive Session Configurations </span> </a> <nav class=md-nav aria-label="ğŸ“Š Common Interactive Session Configurations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-cpu-session class=md-nav__link> <span class=md-ellipsis> Basic CPU Session </span> </a> </li> <li class=md-nav__item> <a href=#gpu-development-session class=md-nav__link> <span class=md-ellipsis> GPU Development Session </span> </a> </li> <li class=md-nav__item> <a href=#multi-gpu-session class=md-nav__link> <span class=md-ellipsis> Multi-GPU Session </span> </a> </li> <li class=md-nav__item> <a href=#high-memory-session class=md-nav__link> <span class=md-ellipsis> High Memory Session </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#working-in-interactive-sessions class=md-nav__link> <span class=md-ellipsis> ğŸ”§ Working in Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#interactive-development-workflow class=md-nav__link> <span class=md-ellipsis> ğŸ“ Interactive Development Workflow </span> </a> <nav class=md-nav aria-label="ğŸ“ Interactive Development Workflow"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-code-development-with-gpu class=md-nav__link> <span class=md-ellipsis> 1. Code Development with GPU </span> </a> </li> <li class=md-nav__item> <a href=#2-interactive-pythonipython class=md-nav__link> <span class=md-ellipsis> 2. Interactive Python/IPython </span> </a> </li> <li class=md-nav__item> <a href=#3-container-development class=md-nav__link> <span class=md-ellipsis> 3. Container Development </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-jupyter-sessions class=md-nav__link> <span class=md-ellipsis> ğŸŒ Interactive Jupyter Sessions </span> </a> <nav class=md-nav aria-label="ğŸŒ Interactive Jupyter Sessions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#launching-jupyter-from-command-line class=md-nav__link> <span class=md-ellipsis> Launching Jupyter from Command Line </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#vscode-remote-development class=md-nav__link> <span class=md-ellipsis> ğŸ’» VSCode Remote Development </span> </a> <nav class=md-nav aria-label="ğŸ’» VSCode Remote Development"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-via-jupyterhub class=md-nav__link> <span class=md-ellipsis> Option 1: Via JupyterHub </span> </a> </li> <li class=md-nav__item> <a href=#option-2-ssh-remote-development class=md-nav__link> <span class=md-ellipsis> Option 2: SSH Remote Development </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#time-limits-and-best-practices class=md-nav__link> <span class=md-ellipsis> â° Time Limits and Best Practices </span> </a> <nav class=md-nav aria-label="â° Time Limits and Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#time-limits class=md-nav__link> <span class=md-ellipsis> Time Limits </span> </a> </li> <li class=md-nav__item> <a href=#best-practices class=md-nav__link> <span class=md-ellipsis> Best Practices </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> â— Common Issues and Solutions </span> </a> </li> <li class=md-nav__item> <a href=#quick-reference-card class=md-nav__link> <span class=md-ellipsis> ğŸ“‹ Quick Reference Card </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#batch-jobs-with-slurm class=md-nav__link> <span class=md-ellipsis> ğŸ“ Batch Jobs with SLURM </span> </a> <nav class=md-nav aria-label="ğŸ“ Batch Jobs with SLURM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#basic-job-script-template class=md-nav__link> <span class=md-ellipsis> ğŸ¯ Basic Job Script Template </span> </a> </li> <li class=md-nav__item> <a href=#gpu-selection-and-memory-requirements class=md-nav__link> <span class=md-ellipsis> ğŸ® GPU Selection and Memory Requirements </span> </a> <nav class=md-nav aria-label="ğŸ® GPU Selection and Memory Requirements"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#requesting-specific-gpu-types class=md-nav__link> <span class=md-ellipsis> Requesting Specific GPU Types </span> </a> </li> <li class=md-nav__item> <a href=#gpu-memory-vs-system-memory class=md-nav__link> <span class=md-ellipsis> GPU Memory vs System Memory </span> </a> </li> <li class=md-nav__item> <a href=#example-large-model-training class=md-nav__link> <span class=md-ellipsis> Example: Large Model Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gpu-training-script class=md-nav__link> <span class=md-ellipsis> ğŸš€ GPU Training Script </span> </a> </li> <li class=md-nav__item> <a href=#multi-gpu-distributed-training class=md-nav__link> <span class=md-ellipsis> ğŸ”¥ Multi-GPU Distributed Training </span> </a> </li> <li class=md-nav__item> <a href=#array-jobs-for-parallel-processing class=md-nav__link> <span class=md-ellipsis> ğŸ”„ Array Jobs for Parallel Processing </span> </a> </li> <li class=md-nav__item> <a href=#container-based-job class=md-nav__link> <span class=md-ellipsis> ğŸ“¦ Container-Based Job </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#job-monitoring-and-management class=md-nav__link> <span class=md-ellipsis> ğŸ” Job Monitoring and Management </span> </a> <nav class=md-nav aria-label="ğŸ” Job Monitoring and Management"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#useful-slurm-commands class=md-nav__link> <span class=md-ellipsis> Useful SLURM Commands </span> </a> </li> <li class=md-nav__item> <a href=#debugging-failed-jobs class=md-nav__link> <span class=md-ellipsis> ğŸ› ï¸ Debugging Failed Jobs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#best-practices_1 class=md-nav__link> <span class=md-ellipsis> ğŸ’¡ Best Practices </span> </a> <nav class=md-nav aria-label="ğŸ’¡ Best Practices"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#best-practices-for-job-scripts class=md-nav__link> <span class=md-ellipsis> Best Practices for Job Scripts </span> </a> </li> <li class=md-nav__item> <a href=#job-script-checklist class=md-nav__link> <span class=md-ellipsis> ğŸ“ Job Script Checklist </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#test-scripts class=md-nav__link> <span class=md-ellipsis> ğŸ§ª Test Scripts </span> </a> <nav class=md-nav aria-label="ğŸ§ª Test Scripts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#interactive-sessions_1 class=md-nav__link> <span class=md-ellipsis> Interactive Sessions </span> </a> </li> <li class=md-nav__item> <a href=#batch-jobs class=md-nav__link> <span class=md-ellipsis> Batch Jobs </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/leggedrobotics/euler-cluster-guide/edit/main/docs/computing-guide.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/leggedrobotics/euler-cluster-guide/raw/main/docs/computing-guide.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=computing-on-euler>Computing on Euler<a class=headerlink href=#computing-on-euler title="Permanent link">&para;</a></h1> <p>This guide covers interactive sessions and batch job submission on the Euler cluster.</p> <h2 id=table-of-contents>Table of Contents<a class=headerlink href=#table-of-contents title="Permanent link">&para;</a></h2> <ol> <li><a href=#interactive-sessions>Interactive Sessions</a></li> <li><a href=#batch-jobs-with-slurm>Batch Jobs with SLURM</a></li> <li><a href=#job-monitoring-and-management>Job Monitoring and Management</a></li> <li><a href=#best-practices>Best Practices</a></li> </ol> <hr> <h2 id=interactive-sessions>ğŸ–¥ï¸ Interactive Sessions<a class=headerlink href=#interactive-sessions title="Permanent link">&para;</a></h2> <p>Interactive sessions on Euler allow you to work directly on compute nodes with allocated resources. This is essential for development, debugging, and testing before submitting batch jobs.</p> <h3 id=requesting-interactive-sessions>ğŸš€ Requesting Interactive Sessions<a class=headerlink href=#requesting-interactive-sessions title="Permanent link">&para;</a></h3> <p>The basic command to request an interactive session is:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>srun<span class=w> </span>--pty<span class=w> </span>bash
</span></code></pre></div> <p>This gives you a basic session with default resources. For more control, specify your requirements:</p> <h3 id=common-interactive-session-configurations>ğŸ“Š Common Interactive Session Configurations<a class=headerlink href=#common-interactive-session-configurations title="Permanent link">&para;</a></h3> <h4 id=basic-cpu-session>Basic CPU Session<a class=headerlink href=#basic-cpu-session title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># 2 hours, 8 CPUs, 32GB RAM</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>srun<span class=w> </span>--time<span class=o>=</span><span class=m>2</span>:00:00<span class=w> </span>--cpus-per-task<span class=o>=</span><span class=m>8</span><span class=w> </span>--mem<span class=o>=</span>32G<span class=w> </span>--pty<span class=w> </span>bash
</span></code></pre></div> <h4 id=gpu-development-session>GPU Development Session<a class=headerlink href=#gpu-development-session title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># 4 hours, 1 GPU, 16 CPUs, 64GB RAM, 100GB local scratch</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>srun<span class=w> </span>--time<span class=o>=</span><span class=m>4</span>:00:00<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--cpus-per-task<span class=o>=</span><span class=m>16</span><span class=w> </span>--mem<span class=o>=</span>64G<span class=w> </span>--tmp<span class=o>=</span>100G<span class=w> </span>--pty<span class=w> </span>bash
</span></code></pre></div> <h4 id=multi-gpu-session>Multi-GPU Session<a class=headerlink href=#multi-gpu-session title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># 2 hours, 4 GPUs, 32 CPUs, 128GB RAM</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>srun<span class=w> </span>--time<span class=o>=</span><span class=m>2</span>:00:00<span class=w> </span>--gpus<span class=o>=</span><span class=m>4</span><span class=w> </span>--cpus-per-task<span class=o>=</span><span class=m>32</span><span class=w> </span>--mem<span class=o>=</span>128G<span class=w> </span>--pty<span class=w> </span>bash
</span></code></pre></div> <h4 id=high-memory-session>High Memory Session<a class=headerlink href=#high-memory-session title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># 1 hour, 4 CPUs, 256GB RAM</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>srun<span class=w> </span>--time<span class=o>=</span><span class=m>1</span>:00:00<span class=w> </span>--cpus-per-task<span class=o>=</span><span class=m>4</span><span class=w> </span>--mem<span class=o>=</span>256G<span class=w> </span>--pty<span class=w> </span>bash
</span></code></pre></div> <h3 id=working-in-interactive-sessions>ğŸ”§ Working in Interactive Sessions<a class=headerlink href=#working-in-interactive-sessions title="Permanent link">&para;</a></h3> <p>Once your session starts, you'll be on a compute node:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Check your allocated resources</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Hostname: </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;CPUs: </span><span class=k>$(</span>nproc<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Memory: </span><span class=k>$(</span>free<span class=w> </span>-h<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>Mem<span class=w> </span><span class=p>|</span><span class=w> </span>awk<span class=w> </span><span class=s1>&#39;{print $2}&#39;</span><span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;GPUs: </span><span class=nv>$CUDA_VISIBLE_DEVICES</span><span class=s2>&quot;</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Local scratch: </span><span class=nv>$TMPDIR</span><span class=s2>&quot;</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=c1># Load necessary modules</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=c1># Activate your conda environment</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>conda<span class=w> </span>activate<span class=w> </span>myenv
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=c1># For GPU sessions, verify CUDA</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>nvidia-smi
</span></code></pre></div> <h3 id=interactive-development-workflow>ğŸ“ Interactive Development Workflow<a class=headerlink href=#interactive-development-workflow title="Permanent link">&para;</a></h3> <h4 id=1-code-development-with-gpu>1. <strong>Code Development with GPU</strong><a class=headerlink href=#1-code-development-with-gpu title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Request GPU session</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>srun<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--mem<span class=o>=</span>32G<span class=w> </span>--time<span class=o>=</span><span class=m>2</span>:00:00<span class=w> </span>--pty<span class=w> </span>bash
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># Navigate to your code</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=nb>cd</span><span class=w> </span>/cluster/home/<span class=nv>$USER</span>/my_project
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=c1># Run and debug</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>python<span class=w> </span>train.py<span class=w> </span>--debug
</span></code></pre></div> <h4 id=2-interactive-pythonipython>2. <strong>Interactive Python/IPython</strong><a class=headerlink href=#2-interactive-pythonipython title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># In your interactive session</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>conda<span class=w> </span>activate<span class=w> </span>myenv
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=c1># Start IPython with GPU support</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>ipython
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=c1># In IPython:</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=c1># &gt;&gt;&gt; import torch</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># &gt;&gt;&gt; torch.cuda.is_available()</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=c1># &gt;&gt;&gt; # Interactive debugging here</span>
</span></code></pre></div> <h4 id=3-container-development>3. <strong>Container Development</strong><a class=headerlink href=#3-container-development title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Request session with local scratch</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>srun<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--tmp<span class=o>=</span>50G<span class=w> </span>--mem<span class=o>=</span>32G<span class=w> </span>--pty<span class=w> </span>bash
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=c1># Extract container to local scratch</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>tar<span class=w> </span>-xf<span class=w> </span>/cluster/work/rsl/<span class=nv>$USER</span>/containers/dev.tar<span class=w> </span>-C<span class=w> </span><span class=nv>$TMPDIR</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=c1># Enter container interactively</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>singularity<span class=w> </span>shell<span class=w> </span>--nv<span class=w> </span><span class=se>\</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=w>    </span>--bind<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>:/project<span class=w> </span><span class=se>\</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=w>    </span><span class=nv>$TMPDIR</span>/dev.sif
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=c1># Now you&#39;re inside the container for testing</span>
</span></code></pre></div> <h3 id=interactive-jupyter-sessions>ğŸŒ Interactive Jupyter Sessions<a class=headerlink href=#interactive-jupyter-sessions title="Permanent link">&para;</a></h3> <p>ETH provides JupyterHub access to Euler:</p> <ol> <li><strong>Access via browser</strong>: https://jupyter.euler.hpc.ethz.ch</li> <li><strong>Login with your nethz credentials</strong></li> <li><strong>Select resources</strong> (GPUs, memory, time)</li> <li><strong>Your notebook runs on Euler compute nodes</strong></li> </ol> <h4 id=launching-jupyter-from-command-line>Launching Jupyter from Command Line<a class=headerlink href=#launching-jupyter-from-command-line title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># In an interactive session</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>srun<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--mem<span class=o>=</span>32G<span class=w> </span>--time<span class=o>=</span><span class=m>4</span>:00:00<span class=w> </span>--pty<span class=w> </span>bash
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=c1># Load modules</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=c1># Start Jupyter (note the token in output)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>jupyter<span class=w> </span>notebook<span class=w> </span>--no-browser<span class=w> </span>--ip<span class=o>=</span><span class=k>$(</span>hostname<span class=w> </span>-i<span class=k>)</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=c1># From your local machine, create SSH tunnel:</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a><span class=c1># ssh -L 8888:compute-node:8888 euler</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=c1># Then open http://localhost:8888 in your browser</span>
</span></code></pre></div> <h3 id=vscode-remote-development>ğŸ’» VSCode Remote Development<a class=headerlink href=#vscode-remote-development title="Permanent link">&para;</a></h3> <p>You can use VSCode directly on Euler nodes:</p> <h4 id=option-1-via-jupyterhub>Option 1: Via JupyterHub<a class=headerlink href=#option-1-via-jupyterhub title="Permanent link">&para;</a></h4> <ol> <li>Go to https://jupyter.euler.hpc.ethz.ch</li> <li>Select "Code Server" instead of JupyterLab</li> <li>VSCode opens in your browser with Euler resources</li> </ol> <h4 id=option-2-ssh-remote-development>Option 2: SSH Remote Development<a class=headerlink href=#option-2-ssh-remote-development title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># First, request an interactive session</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>srun<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--mem<span class=o>=</span>32G<span class=w> </span>--time<span class=o>=</span><span class=m>4</span>:00:00<span class=w> </span>--pty<span class=w> </span>bash
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=c1># Note the compute node name (e.g., eu-g1-001)</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>hostname
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=c1># From your local VSCode:</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a><span class=c1># 1. Install &quot;Remote - SSH&quot; extension</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=c1># 2. Connect to: ssh username@euler</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=c1># 3. Then SSH to the compute node from terminal</span>
</span></code></pre></div> <h3 id=time-limits-and-best-practices>â° Time Limits and Best Practices<a class=headerlink href=#time-limits-and-best-practices title="Permanent link">&para;</a></h3> <h4 id=time-limits>Time Limits<a class=headerlink href=#time-limits title="Permanent link">&para;</a></h4> <ul> <li>Default: 1 hour if not specified</li> <li>Maximum interactive time: 24 hours</li> <li>GPU sessions may have shorter limits during peak usage</li> </ul> <h4 id=best-practices>Best Practices<a class=headerlink href=#best-practices title="Permanent link">&para;</a></h4> <ol> <li><strong>Request only what you need</strong> - Others are waiting for resources</li> <li><strong>Use <code>--tmp</code> for I/O intensive work</strong> - Local scratch is much faster</li> <li><strong>Exit when done</strong> - Don't leave idle sessions</li> <li><strong>Save your work frequently</strong> - Sessions can be terminated</li> <li><strong>Use screen/tmux for long sessions</strong> - Protects against disconnections</li> </ol> <h3 id=common-issues-and-solutions>â— Common Issues and Solutions<a class=headerlink href=#common-issues-and-solutions title="Permanent link">&para;</a></h3> <p><strong>Session won't start (pending)</strong> <div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Check queue status</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>squeue<span class=w> </span>-u<span class=w> </span><span class=nv>$USER</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=c1># Check available resources</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>sinfo<span class=w> </span>-p<span class=w> </span>gpu
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=c1># Try requesting fewer resources or different partition</span>
</span></code></pre></div></p> <p><strong>Disconnection from interactive session</strong> <div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Prevent with screen/tmux</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>screen<span class=w> </span>-S<span class=w> </span>mysession
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>srun<span class=w> </span>--gpus<span class=o>=</span><span class=m>1</span><span class=w> </span>--pty<span class=w> </span>bash
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=c1># Detach: Ctrl+A, D</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=c1># Reattach: screen -r mysession</span>
</span></code></pre></div></p> <p><strong>Out of memory in session</strong> <div class="language-bash highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Monitor memory usage</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>watch<span class=w> </span>-n<span class=w> </span><span class=m>1</span><span class=w> </span>free<span class=w> </span>-h
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=c1># Check your process memory</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>ps<span class=w> </span>aux<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span><span class=nv>$USER</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=c1># Request more memory next time</span>
</span></code></pre></div></p> <h3 id=quick-reference-card>ğŸ“‹ Quick Reference Card<a class=headerlink href=#quick-reference-card title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Task</th> <th>Command</th> </tr> </thead> <tbody> <tr> <td>Basic session</td> <td><code>srun --pty bash</code></td> </tr> <tr> <td>GPU session</td> <td><code>srun --gpus=1 --pty bash</code></td> </tr> <tr> <td>Specific time</td> <td><code>srun --time=4:00:00 --pty bash</code></td> </tr> <tr> <td>More memory</td> <td><code>srun --mem=64G --pty bash</code></td> </tr> <tr> <td>Local scratch</td> <td><code>srun --tmp=100G --pty bash</code></td> </tr> <tr> <td>Check allocation</td> <td><code>scontrol show job $SLURM_JOB_ID</code></td> </tr> <tr> <td>Exit session</td> <td><code>exit</code> or <code>Ctrl+D</code></td> </tr> </tbody> </table> <hr> <h2 id=batch-jobs-with-slurm>ğŸ“ Batch Jobs with SLURM<a class=headerlink href=#batch-jobs-with-slurm title="Permanent link">&para;</a></h2> <p>SLURM batch scripts allow you to submit jobs that run without manual intervention. Here are tested examples for common use cases on the Euler cluster.</p> <h3 id=basic-job-script-template>ğŸ¯ Basic Job Script Template<a class=headerlink href=#basic-job-script-template title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=c1>#SBATCH --job-name=my_job</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=c1>#SBATCH --output=logs/job_%j.out</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=c1>#SBATCH --error=logs/job_%j.err</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=c1>#SBATCH --time=04:00:00</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a><span class=c1>#SBATCH --cpus-per-task=8</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a><span class=c1>#SBATCH --mem-per-cpu=4G</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=c1># Load required modules</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a><span class=c1># Job info</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Job started on </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2> at </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Job ID: </span><span class=nv>$SLURM_JOB_ID</span><span class=s2>&quot;</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>
</span><span id=__span-14-17><a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a><span class=c1># Your commands here</span>
</span><span id=__span-14-18><a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a><span class=nb>cd</span><span class=w> </span>/cluster/home/<span class=nv>$USER</span>/my_project
</span><span id=__span-14-19><a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a>python<span class=w> </span>my_script.py
</span><span id=__span-14-20><a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a>
</span><span id=__span-14-21><a id=__codelineno-14-21 name=__codelineno-14-21 href=#__codelineno-14-21></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Job completed at </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span></code></pre></div> <p>Submit with: <code>sbatch my_job.sh</code></p> <h3 id=gpu-selection-and-memory-requirements>ğŸ® GPU Selection and Memory Requirements<a class=headerlink href=#gpu-selection-and-memory-requirements title="Permanent link">&para;</a></h3> <h4 id=requesting-specific-gpu-types>Requesting Specific GPU Types<a class=headerlink href=#requesting-specific-gpu-types title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Request any available GPU</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=c1>#SBATCH --gpus=1</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=c1># Request specific GPU model</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a><span class=c1>#SBATCH --gpus=nvidia_geforce_rtx_4090:1     # RTX 4090 (24GB VRAM)</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a><span class=c1>#SBATCH --gpus=nvidia_geforce_rtx_3090:1     # RTX 3090 (24GB VRAM)</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=c1>#SBATCH --gpus=nvidia_a100_80gb_pcie:1       # A100 (80GB VRAM)</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a><span class=c1>#SBATCH --gpus=nvidia_a100-pcie-40gb:1       # A100 (40GB VRAM)</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a><span class=c1>#SBATCH --gpus=tesla_v100-sxm2-32gb:1        # V100 (32GB VRAM)</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a><span class=c1># Request multiple GPUs of same type</span>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a><span class=c1>#SBATCH --gpus=nvidia_geforce_rtx_4090:4     # 4x RTX 4090</span>
</span></code></pre></div> <h4 id=gpu-memory-vs-system-memory>GPU Memory vs System Memory<a class=headerlink href=#gpu-memory-vs-system-memory title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># System memory (RAM) - shared by CPUs</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=c1>#SBATCH --mem=64G              # Total memory for job</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a><span class=c1>#SBATCH --mem-per-cpu=8G       # Memory per CPU core</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a><span class=c1># GPU memory (VRAM) is fixed by GPU type:</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a><span class=c1># RTX 4090: 24GB VRAM</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=c1># RTX 3090: 24GB VRAM  </span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=c1># A100: 40GB or 80GB VRAM</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=c1># V100: 32GB VRAM</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=c1># RTX 2080 Ti: 11GB VRAM</span>
</span></code></pre></div> <h4 id=example-large-model-training>Example: Large Model Training<a class=headerlink href=#example-large-model-training title="Permanent link">&para;</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=c1>#SBATCH --job-name=llm-training</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a><span class=c1>#SBATCH --gpus=nvidia_a100_80gb_pcie:1  # Need 80GB VRAM for model</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=c1>#SBATCH --cpus-per-task=32               # Many CPUs for data loading</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=c1>#SBATCH --mem=256G                       # Large system RAM for dataset</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a><span class=c1>#SBATCH --time=72:00:00</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a><span class=c1>#SBATCH --tmp=500G                       # Local scratch for dataset</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a><span class=c1># The A100 80GB GPU allows loading larger models</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a><span class=c1># System RAM (256GB) is for CPU operations and data loading</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a><span class=c1># GPU VRAM (80GB) is for model weights and activations</span>
</span></code></pre></div> <h3 id=gpu-training-script>ğŸš€ GPU Training Script<a class=headerlink href=#gpu-training-script title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=c1>#SBATCH --job-name=gpu-training</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a><span class=c1>#SBATCH --output=logs/train_%j.out</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=c1>#SBATCH --error=logs/train_%j.err</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=c1>#SBATCH --time=24:00:00</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a><span class=c1>#SBATCH --cpus-per-task=16</span>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a><span class=c1>#SBATCH --mem-per-cpu=4G</span>
</span><span id=__span-18-9><a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a><span class=c1>#SBATCH --gpus=1                # Request any available GPU</span>
</span><span id=__span-18-10><a id=__codelineno-18-10 name=__codelineno-18-10 href=#__codelineno-18-10></a><span class=c1>#SBATCH --tmp=100G</span>
</span><span id=__span-18-11><a id=__codelineno-18-11 name=__codelineno-18-11 href=#__codelineno-18-11></a>
</span><span id=__span-18-12><a id=__codelineno-18-12 name=__codelineno-18-12 href=#__codelineno-18-12></a><span class=c1># For specific GPU types, use one of these instead:</span>
</span><span id=__span-18-13><a id=__codelineno-18-13 name=__codelineno-18-13 href=#__codelineno-18-13></a><span class=c1># #SBATCH --gpus=nvidia_geforce_rtx_4090:1     # RTX 4090 (24GB)</span>
</span><span id=__span-18-14><a id=__codelineno-18-14 name=__codelineno-18-14 href=#__codelineno-18-14></a><span class=c1># #SBATCH --gpus=nvidia_geforce_rtx_3090:1     # RTX 3090 (24GB)  </span>
</span><span id=__span-18-15><a id=__codelineno-18-15 name=__codelineno-18-15 href=#__codelineno-18-15></a><span class=c1># #SBATCH --gpus=nvidia_a100_80gb_pcie:1       # A100 80GB</span>
</span><span id=__span-18-16><a id=__codelineno-18-16 name=__codelineno-18-16 href=#__codelineno-18-16></a><span class=c1># #SBATCH --gpus=nvidia_a100-pcie-40gb:1       # A100 40GB</span>
</span><span id=__span-18-17><a id=__codelineno-18-17 name=__codelineno-18-17 href=#__codelineno-18-17></a><span class=c1># #SBATCH --gpus=tesla_v100-sxm2-32gb:1        # V100 32GB</span>
</span><span id=__span-18-18><a id=__codelineno-18-18 name=__codelineno-18-18 href=#__codelineno-18-18></a>
</span><span id=__span-18-19><a id=__codelineno-18-19 name=__codelineno-18-19 href=#__codelineno-18-19></a><span class=c1># Load modules</span>
</span><span id=__span-18-20><a id=__codelineno-18-20 name=__codelineno-18-20 href=#__codelineno-18-20></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-18-21><a id=__codelineno-18-21 name=__codelineno-18-21 href=#__codelineno-18-21></a>
</span><span id=__span-18-22><a id=__codelineno-18-22 name=__codelineno-18-22 href=#__codelineno-18-22></a><span class=c1># Job information</span>
</span><span id=__span-18-23><a id=__codelineno-18-23 name=__codelineno-18-23 href=#__codelineno-18-23></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=========================================&quot;</span>
</span><span id=__span-18-24><a id=__codelineno-18-24 name=__codelineno-18-24 href=#__codelineno-18-24></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;SLURM Job ID: </span><span class=nv>$SLURM_JOB_ID</span><span class=s2>&quot;</span>
</span><span id=__span-18-25><a id=__codelineno-18-25 name=__codelineno-18-25 href=#__codelineno-18-25></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Running on: </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-18-26><a id=__codelineno-18-26 name=__codelineno-18-26 href=#__codelineno-18-26></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Starting at: </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-18-27><a id=__codelineno-18-27 name=__codelineno-18-27 href=#__codelineno-18-27></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;GPU allocation: </span><span class=nv>$CUDA_VISIBLE_DEVICES</span><span class=s2>&quot;</span>
</span><span id=__span-18-28><a id=__codelineno-18-28 name=__codelineno-18-28 href=#__codelineno-18-28></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=========================================&quot;</span>
</span><span id=__span-18-29><a id=__codelineno-18-29 name=__codelineno-18-29 href=#__codelineno-18-29></a>
</span><span id=__span-18-30><a id=__codelineno-18-30 name=__codelineno-18-30 href=#__codelineno-18-30></a><span class=c1># Copy dataset to local scratch for faster I/O</span>
</span><span id=__span-18-31><a id=__codelineno-18-31 name=__codelineno-18-31 href=#__codelineno-18-31></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Copying dataset to local scratch...&quot;</span>
</span><span id=__span-18-32><a id=__codelineno-18-32 name=__codelineno-18-32 href=#__codelineno-18-32></a>cp<span class=w> </span>-r<span class=w> </span>/cluster/scratch/<span class=nv>$USER</span>/datasets/my_dataset<span class=w> </span><span class=nv>$TMPDIR</span>/
</span><span id=__span-18-33><a id=__codelineno-18-33 name=__codelineno-18-33 href=#__codelineno-18-33></a>
</span><span id=__span-18-34><a id=__codelineno-18-34 name=__codelineno-18-34 href=#__codelineno-18-34></a><span class=c1># Activate conda environment</span>
</span><span id=__span-18-35><a id=__codelineno-18-35 name=__codelineno-18-35 href=#__codelineno-18-35></a><span class=nb>source</span><span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/miniconda3/bin/activate
</span><span id=__span-18-36><a id=__codelineno-18-36 name=__codelineno-18-36 href=#__codelineno-18-36></a>conda<span class=w> </span>activate<span class=w> </span>ml_env
</span><span id=__span-18-37><a id=__codelineno-18-37 name=__codelineno-18-37 href=#__codelineno-18-37></a>
</span><span id=__span-18-38><a id=__codelineno-18-38 name=__codelineno-18-38 href=#__codelineno-18-38></a><span class=c1># Run training</span>
</span><span id=__span-18-39><a id=__codelineno-18-39 name=__codelineno-18-39 href=#__codelineno-18-39></a><span class=nb>cd</span><span class=w> </span>/cluster/home/<span class=nv>$USER</span>/my_ml_project
</span><span id=__span-18-40><a id=__codelineno-18-40 name=__codelineno-18-40 href=#__codelineno-18-40></a>python<span class=w> </span>train.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-18-41><a id=__codelineno-18-41 name=__codelineno-18-41 href=#__codelineno-18-41></a><span class=w>    </span>--data-dir<span class=w> </span><span class=nv>$TMPDIR</span>/my_dataset<span class=w> </span><span class=se>\</span>
</span><span id=__span-18-42><a id=__codelineno-18-42 name=__codelineno-18-42 href=#__codelineno-18-42></a><span class=w>    </span>--output-dir<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/results/<span class=nv>$SLURM_JOB_ID</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-18-43><a id=__codelineno-18-43 name=__codelineno-18-43 href=#__codelineno-18-43></a><span class=w>    </span>--epochs<span class=w> </span><span class=m>100</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-18-44><a id=__codelineno-18-44 name=__codelineno-18-44 href=#__codelineno-18-44></a><span class=w>    </span>--batch-size<span class=w> </span><span class=m>64</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-18-45><a id=__codelineno-18-45 name=__codelineno-18-45 href=#__codelineno-18-45></a><span class=w>    </span>--lr<span class=w> </span><span class=m>0</span>.001
</span><span id=__span-18-46><a id=__codelineno-18-46 name=__codelineno-18-46 href=#__codelineno-18-46></a>
</span><span id=__span-18-47><a id=__codelineno-18-47 name=__codelineno-18-47 href=#__codelineno-18-47></a><span class=c1># Copy final results back</span>
</span><span id=__span-18-48><a id=__codelineno-18-48 name=__codelineno-18-48 href=#__codelineno-18-48></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Copying results...&quot;</span>
</span><span id=__span-18-49><a id=__codelineno-18-49 name=__codelineno-18-49 href=#__codelineno-18-49></a>cp<span class=w> </span>-r<span class=w> </span><span class=nv>$TMPDIR</span>/checkpoints/*<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/checkpoints/
</span><span id=__span-18-50><a id=__codelineno-18-50 name=__codelineno-18-50 href=#__codelineno-18-50></a>
</span><span id=__span-18-51><a id=__codelineno-18-51 name=__codelineno-18-51 href=#__codelineno-18-51></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Job completed at </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span></code></pre></div> <h3 id=multi-gpu-distributed-training>ğŸ”¥ Multi-GPU Distributed Training<a class=headerlink href=#multi-gpu-distributed-training title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=c1>#SBATCH --job-name=distributed-training</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=c1>#SBATCH --output=logs/distributed_%j.out</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=c1>#SBATCH --error=logs/distributed_%j.err</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=c1>#SBATCH --time=48:00:00</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a><span class=c1>#SBATCH --cpus-per-task=32</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=c1>#SBATCH --mem-per-cpu=8G</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a><span class=c1>#SBATCH --gpus=4</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a><span class=c1>#SBATCH --tmp=200G</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a>
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Multi-GPU training on </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-19-15><a id=__codelineno-19-15 name=__codelineno-19-15 href=#__codelineno-19-15></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;GPUs: </span><span class=nv>$CUDA_VISIBLE_DEVICES</span><span class=s2>&quot;</span>
</span><span id=__span-19-16><a id=__codelineno-19-16 name=__codelineno-19-16 href=#__codelineno-19-16></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Number of GPUs: </span><span class=k>$(</span><span class=nb>echo</span><span class=w> </span><span class=nv>$CUDA_VISIBLE_DEVICES</span><span class=w> </span><span class=p>|</span><span class=w> </span>tr<span class=w> </span><span class=s1>&#39;,&#39;</span><span class=w> </span><span class=s1>&#39;\n&#39;</span><span class=w> </span><span class=p>|</span><span class=w> </span>wc<span class=w> </span>-l<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-19-17><a id=__codelineno-19-17 name=__codelineno-19-17 href=#__codelineno-19-17></a>
</span><span id=__span-19-18><a id=__codelineno-19-18 name=__codelineno-19-18 href=#__codelineno-19-18></a><span class=c1># Prepare data on local scratch</span>
</span><span id=__span-19-19><a id=__codelineno-19-19 name=__codelineno-19-19 href=#__codelineno-19-19></a>tar<span class=w> </span>-xf<span class=w> </span>/cluster/scratch/<span class=nv>$USER</span>/datasets/imagenet.tar<span class=w> </span>-C<span class=w> </span><span class=nv>$TMPDIR</span>/
</span><span id=__span-19-20><a id=__codelineno-19-20 name=__codelineno-19-20 href=#__codelineno-19-20></a>
</span><span id=__span-19-21><a id=__codelineno-19-21 name=__codelineno-19-21 href=#__codelineno-19-21></a><span class=c1># Activate environment</span>
</span><span id=__span-19-22><a id=__codelineno-19-22 name=__codelineno-19-22 href=#__codelineno-19-22></a><span class=nb>source</span><span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/miniconda3/bin/activate
</span><span id=__span-19-23><a id=__codelineno-19-23 name=__codelineno-19-23 href=#__codelineno-19-23></a>conda<span class=w> </span>activate<span class=w> </span>pytorch_env
</span><span id=__span-19-24><a id=__codelineno-19-24 name=__codelineno-19-24 href=#__codelineno-19-24></a>
</span><span id=__span-19-25><a id=__codelineno-19-25 name=__codelineno-19-25 href=#__codelineno-19-25></a><span class=c1># Set distributed training environment variables</span>
</span><span id=__span-19-26><a id=__codelineno-19-26 name=__codelineno-19-26 href=#__codelineno-19-26></a><span class=nb>export</span><span class=w> </span><span class=nv>MASTER_ADDR</span><span class=o>=</span><span class=k>$(</span>hostname<span class=k>)</span>
</span><span id=__span-19-27><a id=__codelineno-19-27 name=__codelineno-19-27 href=#__codelineno-19-27></a><span class=nb>export</span><span class=w> </span><span class=nv>MASTER_PORT</span><span class=o>=</span><span class=m>29500</span>
</span><span id=__span-19-28><a id=__codelineno-19-28 name=__codelineno-19-28 href=#__codelineno-19-28></a><span class=nb>export</span><span class=w> </span><span class=nv>WORLD_SIZE</span><span class=o>=</span><span class=m>4</span>
</span><span id=__span-19-29><a id=__codelineno-19-29 name=__codelineno-19-29 href=#__codelineno-19-29></a>
</span><span id=__span-19-30><a id=__codelineno-19-30 name=__codelineno-19-30 href=#__codelineno-19-30></a><span class=c1># Run distributed training</span>
</span><span id=__span-19-31><a id=__codelineno-19-31 name=__codelineno-19-31 href=#__codelineno-19-31></a><span class=nb>cd</span><span class=w> </span>/cluster/home/<span class=nv>$USER</span>/vision_project
</span><span id=__span-19-32><a id=__codelineno-19-32 name=__codelineno-19-32 href=#__codelineno-19-32></a>python<span class=w> </span>-m<span class=w> </span>torch.distributed.run<span class=w> </span><span class=se>\</span>
</span><span id=__span-19-33><a id=__codelineno-19-33 name=__codelineno-19-33 href=#__codelineno-19-33></a><span class=w>    </span>--nproc_per_node<span class=o>=</span><span class=m>4</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-19-34><a id=__codelineno-19-34 name=__codelineno-19-34 href=#__codelineno-19-34></a><span class=w>    </span>--master_addr<span class=o>=</span><span class=nv>$MASTER_ADDR</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-19-35><a id=__codelineno-19-35 name=__codelineno-19-35 href=#__codelineno-19-35></a><span class=w>    </span>--master_port<span class=o>=</span><span class=nv>$MASTER_PORT</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-19-36><a id=__codelineno-19-36 name=__codelineno-19-36 href=#__codelineno-19-36></a><span class=w>    </span>train_distributed.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-19-37><a id=__codelineno-19-37 name=__codelineno-19-37 href=#__codelineno-19-37></a><span class=w>    </span>--data<span class=w> </span><span class=nv>$TMPDIR</span>/imagenet<span class=w> </span><span class=se>\</span>
</span><span id=__span-19-38><a id=__codelineno-19-38 name=__codelineno-19-38 href=#__codelineno-19-38></a><span class=w>    </span>--output<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/results/<span class=nv>$SLURM_JOB_ID</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-19-39><a id=__codelineno-19-39 name=__codelineno-19-39 href=#__codelineno-19-39></a><span class=w>    </span>--sync-bn<span class=w> </span><span class=se>\</span>
</span><span id=__span-19-40><a id=__codelineno-19-40 name=__codelineno-19-40 href=#__codelineno-19-40></a><span class=w>    </span>--amp
</span><span id=__span-19-41><a id=__codelineno-19-41 name=__codelineno-19-41 href=#__codelineno-19-41></a>
</span><span id=__span-19-42><a id=__codelineno-19-42 name=__codelineno-19-42 href=#__codelineno-19-42></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Training completed at </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span></code></pre></div> <h3 id=array-jobs-for-parallel-processing>ğŸ”„ Array Jobs for Parallel Processing<a class=headerlink href=#array-jobs-for-parallel-processing title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=c1>#SBATCH --job-name=param-sweep</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=c1>#SBATCH --output=logs/array_%A_%a.out</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a><span class=c1>#SBATCH --error=logs/array_%A_%a.err</span>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a><span class=c1>#SBATCH --time=02:00:00</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a><span class=c1>#SBATCH --array=1-50</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a><span class=c1>#SBATCH --cpus-per-task=4</span>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a><span class=c1>#SBATCH --mem-per-cpu=4G</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a><span class=c1>#SBATCH --gpus=1</span>
</span><span id=__span-20-11><a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a>
</span><span id=__span-20-12><a id=__codelineno-20-12 name=__codelineno-20-12 href=#__codelineno-20-12></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-20-13><a id=__codelineno-20-13 name=__codelineno-20-13 href=#__codelineno-20-13></a>
</span><span id=__span-20-14><a id=__codelineno-20-14 name=__codelineno-20-14 href=#__codelineno-20-14></a><span class=c1># Array job information</span>
</span><span id=__span-20-15><a id=__codelineno-20-15 name=__codelineno-20-15 href=#__codelineno-20-15></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Array Job ID: </span><span class=nv>$SLURM_ARRAY_JOB_ID</span><span class=s2>&quot;</span>
</span><span id=__span-20-16><a id=__codelineno-20-16 name=__codelineno-20-16 href=#__codelineno-20-16></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Array Task ID: </span><span class=nv>$SLURM_ARRAY_TASK_ID</span><span class=s2>&quot;</span>
</span><span id=__span-20-17><a id=__codelineno-20-17 name=__codelineno-20-17 href=#__codelineno-20-17></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Running on: </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-20-18><a id=__codelineno-20-18 name=__codelineno-20-18 href=#__codelineno-20-18></a>
</span><span id=__span-20-19><a id=__codelineno-20-19 name=__codelineno-20-19 href=#__codelineno-20-19></a><span class=c1># Define parameter arrays</span>
</span><span id=__span-20-20><a id=__codelineno-20-20 name=__codelineno-20-20 href=#__codelineno-20-20></a><span class=nv>learning_rates</span><span class=o>=(</span><span class=m>0</span>.001<span class=w> </span><span class=m>0</span>.0001<span class=w> </span><span class=m>0</span>.00001<span class=w> </span><span class=m>0</span>.01<span class=w> </span><span class=m>0</span>.1<span class=o>)</span>
</span><span id=__span-20-21><a id=__codelineno-20-21 name=__codelineno-20-21 href=#__codelineno-20-21></a><span class=nv>batch_sizes</span><span class=o>=(</span><span class=m>16</span><span class=w> </span><span class=m>32</span><span class=w> </span><span class=m>64</span><span class=w> </span><span class=m>128</span><span class=w> </span><span class=m>256</span><span class=o>)</span>
</span><span id=__span-20-22><a id=__codelineno-20-22 name=__codelineno-20-22 href=#__codelineno-20-22></a>
</span><span id=__span-20-23><a id=__codelineno-20-23 name=__codelineno-20-23 href=#__codelineno-20-23></a><span class=c1># Calculate indices for 2D parameter grid</span>
</span><span id=__span-20-24><a id=__codelineno-20-24 name=__codelineno-20-24 href=#__codelineno-20-24></a><span class=nv>lr_index</span><span class=o>=</span><span class=k>$((</span><span class=w> </span><span class=o>(</span><span class=nv>$SLURM_ARRAY_TASK_ID</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=m>1</span><span class=o>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=si>${#</span><span class=nv>batch_sizes</span><span class=p>[@]</span><span class=si>}</span><span class=w> </span><span class=k>))</span>
</span><span id=__span-20-25><a id=__codelineno-20-25 name=__codelineno-20-25 href=#__codelineno-20-25></a><span class=nv>bs_index</span><span class=o>=</span><span class=k>$((</span><span class=w> </span><span class=o>(</span><span class=nv>$SLURM_ARRAY_TASK_ID</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=m>1</span><span class=o>)</span><span class=w> </span><span class=o>%</span><span class=w> </span><span class=si>${#</span><span class=nv>batch_sizes</span><span class=p>[@]</span><span class=si>}</span><span class=w> </span><span class=k>))</span>
</span><span id=__span-20-26><a id=__codelineno-20-26 name=__codelineno-20-26 href=#__codelineno-20-26></a>
</span><span id=__span-20-27><a id=__codelineno-20-27 name=__codelineno-20-27 href=#__codelineno-20-27></a><span class=nv>LR</span><span class=o>=</span><span class=si>${</span><span class=nv>learning_rates</span><span class=p>[</span><span class=nv>$lr_index</span><span class=p>]</span><span class=si>}</span>
</span><span id=__span-20-28><a id=__codelineno-20-28 name=__codelineno-20-28 href=#__codelineno-20-28></a><span class=nv>BS</span><span class=o>=</span><span class=si>${</span><span class=nv>batch_sizes</span><span class=p>[</span><span class=nv>$bs_index</span><span class=p>]</span><span class=si>}</span>
</span><span id=__span-20-29><a id=__codelineno-20-29 name=__codelineno-20-29 href=#__codelineno-20-29></a>
</span><span id=__span-20-30><a id=__codelineno-20-30 name=__codelineno-20-30 href=#__codelineno-20-30></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Testing LR=</span><span class=nv>$LR</span><span class=s2>, Batch Size=</span><span class=nv>$BS</span><span class=s2>&quot;</span>
</span><span id=__span-20-31><a id=__codelineno-20-31 name=__codelineno-20-31 href=#__codelineno-20-31></a>
</span><span id=__span-20-32><a id=__codelineno-20-32 name=__codelineno-20-32 href=#__codelineno-20-32></a><span class=c1># Activate environment</span>
</span><span id=__span-20-33><a id=__codelineno-20-33 name=__codelineno-20-33 href=#__codelineno-20-33></a><span class=nb>source</span><span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/miniconda3/bin/activate
</span><span id=__span-20-34><a id=__codelineno-20-34 name=__codelineno-20-34 href=#__codelineno-20-34></a>conda<span class=w> </span>activate<span class=w> </span>ml_env
</span><span id=__span-20-35><a id=__codelineno-20-35 name=__codelineno-20-35 href=#__codelineno-20-35></a>
</span><span id=__span-20-36><a id=__codelineno-20-36 name=__codelineno-20-36 href=#__codelineno-20-36></a><span class=c1># Run experiment</span>
</span><span id=__span-20-37><a id=__codelineno-20-37 name=__codelineno-20-37 href=#__codelineno-20-37></a><span class=nb>cd</span><span class=w> </span>/cluster/home/<span class=nv>$USER</span>/hyperparameter_search
</span><span id=__span-20-38><a id=__codelineno-20-38 name=__codelineno-20-38 href=#__codelineno-20-38></a>python<span class=w> </span>train.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-20-39><a id=__codelineno-20-39 name=__codelineno-20-39 href=#__codelineno-20-39></a><span class=w>    </span>--lr<span class=w> </span><span class=nv>$LR</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-20-40><a id=__codelineno-20-40 name=__codelineno-20-40 href=#__codelineno-20-40></a><span class=w>    </span>--batch-size<span class=w> </span><span class=nv>$BS</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-20-41><a id=__codelineno-20-41 name=__codelineno-20-41 href=#__codelineno-20-41></a><span class=w>    </span>--epochs<span class=w> </span><span class=m>20</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-20-42><a id=__codelineno-20-42 name=__codelineno-20-42 href=#__codelineno-20-42></a><span class=w>    </span>--output<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/hp_search/lr<span class=si>${</span><span class=nv>LR</span><span class=si>}</span>_bs<span class=si>${</span><span class=nv>BS</span><span class=si>}</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-20-43><a id=__codelineno-20-43 name=__codelineno-20-43 href=#__codelineno-20-43></a><span class=w>    </span>--seed<span class=w> </span><span class=nv>$SLURM_ARRAY_TASK_ID</span>
</span></code></pre></div> <p>Submit array job: <code>sbatch --array=1-25 array_job.sh</code></p> <h3 id=container-based-job>ğŸ“¦ Container-Based Job<a class=headerlink href=#container-based-job title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a><span class=c1>#SBATCH --job-name=container-job</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=c1>#SBATCH --output=logs/container_%j.out</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a><span class=c1>#SBATCH --error=logs/container_%j.err</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a><span class=c1>#SBATCH --time=12:00:00</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a><span class=c1>#SBATCH --cpus-per-task=8</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a><span class=c1>#SBATCH --mem-per-cpu=8G</span>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a><span class=c1>#SBATCH --gpus=2</span>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a><span class=c1>#SBATCH --tmp=150G</span>
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a>
</span><span id=__span-21-12><a id=__codelineno-21-12 name=__codelineno-21-12 href=#__codelineno-21-12></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-21-13><a id=__codelineno-21-13 name=__codelineno-21-13 href=#__codelineno-21-13></a>
</span><span id=__span-21-14><a id=__codelineno-21-14 name=__codelineno-21-14 href=#__codelineno-21-14></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Container job started on </span><span class=k>$(</span>hostname<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-21-15><a id=__codelineno-21-15 name=__codelineno-21-15 href=#__codelineno-21-15></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Extracting container to local scratch...&quot;</span>
</span><span id=__span-21-16><a id=__codelineno-21-16 name=__codelineno-21-16 href=#__codelineno-21-16></a>
</span><span id=__span-21-17><a id=__codelineno-21-17 name=__codelineno-21-17 href=#__codelineno-21-17></a><span class=c1># Extract container (much faster than running from /cluster/work)</span>
</span><span id=__span-21-18><a id=__codelineno-21-18 name=__codelineno-21-18 href=#__codelineno-21-18></a><span class=nb>time</span><span class=w> </span>tar<span class=w> </span>-xf<span class=w> </span>/cluster/work/rsl/<span class=nv>$USER</span>/containers/ml_stack.tar<span class=w> </span>-C<span class=w> </span><span class=nv>$TMPDIR</span>
</span><span id=__span-21-19><a id=__codelineno-21-19 name=__codelineno-21-19 href=#__codelineno-21-19></a>
</span><span id=__span-21-20><a id=__codelineno-21-20 name=__codelineno-21-20 href=#__codelineno-21-20></a><span class=c1># Prepare data</span>
</span><span id=__span-21-21><a id=__codelineno-21-21 name=__codelineno-21-21 href=#__codelineno-21-21></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Preparing data...&quot;</span>
</span><span id=__span-21-22><a id=__codelineno-21-22 name=__codelineno-21-22 href=#__codelineno-21-22></a>mkdir<span class=w> </span>-p<span class=w> </span><span class=nv>$TMPDIR</span>/data
</span><span id=__span-21-23><a id=__codelineno-21-23 name=__codelineno-21-23 href=#__codelineno-21-23></a>cp<span class=w> </span>-r<span class=w> </span>/cluster/scratch/<span class=nv>$USER</span>/datasets/train_data<span class=w> </span><span class=nv>$TMPDIR</span>/data/
</span><span id=__span-21-24><a id=__codelineno-21-24 name=__codelineno-21-24 href=#__codelineno-21-24></a>
</span><span id=__span-21-25><a id=__codelineno-21-25 name=__codelineno-21-25 href=#__codelineno-21-25></a><span class=c1># Run training in container</span>
</span><span id=__span-21-26><a id=__codelineno-21-26 name=__codelineno-21-26 href=#__codelineno-21-26></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Starting training...&quot;</span>
</span><span id=__span-21-27><a id=__codelineno-21-27 name=__codelineno-21-27 href=#__codelineno-21-27></a>singularity<span class=w> </span><span class=nb>exec</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-28><a id=__codelineno-21-28 name=__codelineno-21-28 href=#__codelineno-21-28></a><span class=w>    </span>--nv<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-29><a id=__codelineno-21-29 name=__codelineno-21-29 href=#__codelineno-21-29></a><span class=w>    </span>--bind<span class=w> </span><span class=nv>$TMPDIR</span>/data:/data:ro<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-30><a id=__codelineno-21-30 name=__codelineno-21-30 href=#__codelineno-21-30></a><span class=w>    </span>--bind<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/results/<span class=nv>$SLURM_JOB_ID</span>:/output<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-31><a id=__codelineno-21-31 name=__codelineno-21-31 href=#__codelineno-21-31></a><span class=w>    </span>--bind<span class=w> </span>/cluster/project/rsl/<span class=nv>$USER</span>/checkpoints:/checkpoints<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-32><a id=__codelineno-21-32 name=__codelineno-21-32 href=#__codelineno-21-32></a><span class=w>    </span><span class=nv>$TMPDIR</span>/ml_stack.sif<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-33><a id=__codelineno-21-33 name=__codelineno-21-33 href=#__codelineno-21-33></a><span class=w>    </span>python<span class=w> </span>/app/train.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-34><a id=__codelineno-21-34 name=__codelineno-21-34 href=#__codelineno-21-34></a><span class=w>        </span>--data<span class=w> </span>/data/train_data<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-35><a id=__codelineno-21-35 name=__codelineno-21-35 href=#__codelineno-21-35></a><span class=w>        </span>--output<span class=w> </span>/output<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-36><a id=__codelineno-21-36 name=__codelineno-21-36 href=#__codelineno-21-36></a><span class=w>        </span>--checkpoint-dir<span class=w> </span>/checkpoints<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-37><a id=__codelineno-21-37 name=__codelineno-21-37 href=#__codelineno-21-37></a><span class=w>        </span>--resume-from<span class=w> </span>latest
</span><span id=__span-21-38><a id=__codelineno-21-38 name=__codelineno-21-38 href=#__codelineno-21-38></a>
</span><span id=__span-21-39><a id=__codelineno-21-39 name=__codelineno-21-39 href=#__codelineno-21-39></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Job completed at </span><span class=k>$(</span>date<span class=k>)</span><span class=s2>&quot;</span>
</span></code></pre></div> <hr> <h2 id=job-monitoring-and-management>ğŸ” Job Monitoring and Management<a class=headerlink href=#job-monitoring-and-management title="Permanent link">&para;</a></h2> <h3 id=useful-slurm-commands>Useful SLURM Commands<a class=headerlink href=#useful-slurm-commands title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># Submit job</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>sbatch<span class=w> </span>my_job.sh
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=c1># Check job status</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>squeue<span class=w> </span>-u<span class=w> </span><span class=nv>$USER</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=c1># Detailed job info</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a>scontrol<span class=w> </span>show<span class=w> </span>job<span class=w> </span>&lt;job_id&gt;
</span><span id=__span-22-9><a id=__codelineno-22-9 name=__codelineno-22-9 href=#__codelineno-22-9></a>
</span><span id=__span-22-10><a id=__codelineno-22-10 name=__codelineno-22-10 href=#__codelineno-22-10></a><span class=c1># Cancel job</span>
</span><span id=__span-22-11><a id=__codelineno-22-11 name=__codelineno-22-11 href=#__codelineno-22-11></a>scancel<span class=w> </span>&lt;job_id&gt;
</span><span id=__span-22-12><a id=__codelineno-22-12 name=__codelineno-22-12 href=#__codelineno-22-12></a>
</span><span id=__span-22-13><a id=__codelineno-22-13 name=__codelineno-22-13 href=#__codelineno-22-13></a><span class=c1># Cancel all your jobs</span>
</span><span id=__span-22-14><a id=__codelineno-22-14 name=__codelineno-22-14 href=#__codelineno-22-14></a>scancel<span class=w> </span>-u<span class=w> </span><span class=nv>$USER</span>
</span><span id=__span-22-15><a id=__codelineno-22-15 name=__codelineno-22-15 href=#__codelineno-22-15></a>
</span><span id=__span-22-16><a id=__codelineno-22-16 name=__codelineno-22-16 href=#__codelineno-22-16></a><span class=c1># View job efficiency after completion</span>
</span><span id=__span-22-17><a id=__codelineno-22-17 name=__codelineno-22-17 href=#__codelineno-22-17></a>seff<span class=w> </span>&lt;job_id&gt;
</span><span id=__span-22-18><a id=__codelineno-22-18 name=__codelineno-22-18 href=#__codelineno-22-18></a>
</span><span id=__span-22-19><a id=__codelineno-22-19 name=__codelineno-22-19 href=#__codelineno-22-19></a><span class=c1># Monitor job in real-time</span>
</span><span id=__span-22-20><a id=__codelineno-22-20 name=__codelineno-22-20 href=#__codelineno-22-20></a>watch<span class=w> </span>-n<span class=w> </span><span class=m>10</span><span class=w> </span>squeue<span class=w> </span>-u<span class=w> </span><span class=nv>$USER</span>
</span></code></pre></div> <h3 id=debugging-failed-jobs>ğŸ› ï¸ Debugging Failed Jobs<a class=headerlink href=#debugging-failed-jobs title="Permanent link">&para;</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=ch>#!/bin/bash</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a><span class=c1>#SBATCH --job-name=debug-job</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=c1>#SBATCH --output=logs/debug_%j.out</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a><span class=c1>#SBATCH --error=logs/debug_%j.err</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a><span class=c1>#SBATCH --time=00:30:00</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a><span class=c1>#SBATCH --ntasks=1</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=c1>#SBATCH --cpus-per-task=4</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a><span class=c1>#SBATCH --mem-per-cpu=4G</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a><span class=c1>#SBATCH --gpus=1</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a><span class=c1># Enable bash debugging</span>
</span><span id=__span-23-12><a id=__codelineno-23-12 name=__codelineno-23-12 href=#__codelineno-23-12></a><span class=nb>set</span><span class=w> </span>-e<span class=w>  </span><span class=c1># Exit on error</span>
</span><span id=__span-23-13><a id=__codelineno-23-13 name=__codelineno-23-13 href=#__codelineno-23-13></a><span class=nb>set</span><span class=w> </span>-u<span class=w>  </span><span class=c1># Exit on undefined variable</span>
</span><span id=__span-23-14><a id=__codelineno-23-14 name=__codelineno-23-14 href=#__codelineno-23-14></a><span class=nb>set</span><span class=w> </span>-x<span class=w>  </span><span class=c1># Print commands as they execute</span>
</span><span id=__span-23-15><a id=__codelineno-23-15 name=__codelineno-23-15 href=#__codelineno-23-15></a>
</span><span id=__span-23-16><a id=__codelineno-23-16 name=__codelineno-23-16 href=#__codelineno-23-16></a>module<span class=w> </span>load<span class=w> </span>eth_proxy
</span><span id=__span-23-17><a id=__codelineno-23-17 name=__codelineno-23-17 href=#__codelineno-23-17></a>
</span><span id=__span-23-18><a id=__codelineno-23-18 name=__codelineno-23-18 href=#__codelineno-23-18></a><span class=c1># Print environment for debugging</span>
</span><span id=__span-23-19><a id=__codelineno-23-19 name=__codelineno-23-19 href=#__codelineno-23-19></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=== Environment ===&quot;</span>
</span><span id=__span-23-20><a id=__codelineno-23-20 name=__codelineno-23-20 href=#__codelineno-23-20></a>env<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>SLURM
</span><span id=__span-23-21><a id=__codelineno-23-21 name=__codelineno-23-21 href=#__codelineno-23-21></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=== GPU Info ===&quot;</span>
</span><span id=__span-23-22><a id=__codelineno-23-22 name=__codelineno-23-22 href=#__codelineno-23-22></a>nvidia-smi
</span><span id=__span-23-23><a id=__codelineno-23-23 name=__codelineno-23-23 href=#__codelineno-23-23></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=== Memory Info ===&quot;</span>
</span><span id=__span-23-24><a id=__codelineno-23-24 name=__codelineno-23-24 href=#__codelineno-23-24></a>free<span class=w> </span>-h
</span><span id=__span-23-25><a id=__codelineno-23-25 name=__codelineno-23-25 href=#__codelineno-23-25></a><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;=== Disk Space ===&quot;</span>
</span><span id=__span-23-26><a id=__codelineno-23-26 name=__codelineno-23-26 href=#__codelineno-23-26></a>df<span class=w> </span>-h<span class=w> </span><span class=nv>$TMPDIR</span>
</span><span id=__span-23-27><a id=__codelineno-23-27 name=__codelineno-23-27 href=#__codelineno-23-27></a>
</span><span id=__span-23-28><a id=__codelineno-23-28 name=__codelineno-23-28 href=#__codelineno-23-28></a><span class=c1># Your actual commands with error checking</span>
</span><span id=__span-23-29><a id=__codelineno-23-29 name=__codelineno-23-29 href=#__codelineno-23-29></a><span class=k>if</span><span class=w> </span>!<span class=w> </span>python<span class=w> </span>--version<span class=p>;</span><span class=w> </span><span class=k>then</span>
</span><span id=__span-23-30><a id=__codelineno-23-30 name=__codelineno-23-30 href=#__codelineno-23-30></a><span class=w>    </span><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Python not found!&quot;</span>
</span><span id=__span-23-31><a id=__codelineno-23-31 name=__codelineno-23-31 href=#__codelineno-23-31></a><span class=w>    </span><span class=nb>exit</span><span class=w> </span><span class=m>1</span>
</span><span id=__span-23-32><a id=__codelineno-23-32 name=__codelineno-23-32 href=#__codelineno-23-32></a><span class=k>fi</span>
</span><span id=__span-23-33><a id=__codelineno-23-33 name=__codelineno-23-33 href=#__codelineno-23-33></a>
</span><span id=__span-23-34><a id=__codelineno-23-34 name=__codelineno-23-34 href=#__codelineno-23-34></a><span class=c1># Run with explicit error handling</span>
</span><span id=__span-23-35><a id=__codelineno-23-35 name=__codelineno-23-35 href=#__codelineno-23-35></a>python<span class=w> </span>my_script.py<span class=w> </span><span class=o>||</span><span class=w> </span><span class=o>{</span>
</span><span id=__span-23-36><a id=__codelineno-23-36 name=__codelineno-23-36 href=#__codelineno-23-36></a><span class=w>    </span><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Script failed with exit code </span><span class=nv>$?</span><span class=s2>&quot;</span>
</span><span id=__span-23-37><a id=__codelineno-23-37 name=__codelineno-23-37 href=#__codelineno-23-37></a><span class=w>    </span><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Current directory: </span><span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-23-38><a id=__codelineno-23-38 name=__codelineno-23-38 href=#__codelineno-23-38></a><span class=w>    </span><span class=nb>echo</span><span class=w> </span><span class=s2>&quot;Files present: </span><span class=k>$(</span>ls<span class=w> </span>-la<span class=k>)</span><span class=s2>&quot;</span>
</span><span id=__span-23-39><a id=__codelineno-23-39 name=__codelineno-23-39 href=#__codelineno-23-39></a><span class=w>    </span><span class=nb>exit</span><span class=w> </span><span class=m>1</span>
</span><span id=__span-23-40><a id=__codelineno-23-40 name=__codelineno-23-40 href=#__codelineno-23-40></a><span class=o>}</span>
</span></code></pre></div> <hr> <h2 id=best-practices_1>ğŸ’¡ Best Practices<a class=headerlink href=#best-practices_1 title="Permanent link">&para;</a></h2> <h3 id=best-practices-for-job-scripts>Best Practices for Job Scripts<a class=headerlink href=#best-practices-for-job-scripts title="Permanent link">&para;</a></h3> <ol> <li><strong>Always specify time limits</strong> - Jobs without time limits may be deprioritized</li> <li><strong>Create log directories</strong> - <code>mkdir -p logs</code> before submitting</li> <li><strong>Use local scratch ($TMPDIR)</strong> - Much faster than network storage</li> <li><strong>Request appropriate resources</strong> - Don't over-request, it delays your job</li> <li><strong>Use job arrays</strong> - For embarrassingly parallel tasks</li> <li><strong>Add error handling</strong> - Check exit codes and add recovery logic</li> </ol> <h3 id=job-script-checklist>ğŸ“ Job Script Checklist<a class=headerlink href=#job-script-checklist title="Permanent link">&para;</a></h3> <p>Before submitting your job, verify:</p> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Shebang line: <code>#!/bin/bash</code></li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Job name is descriptive</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Output/error paths exist (<code>mkdir -p logs</code>)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Time limit is appropriate</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Memory request is reasonable</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> GPU request matches your code</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Module <code>eth_proxy</code> is loaded</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Paths use <code>$USER</code> variable</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Local scratch <code>$TMPDIR</code> used for I/O</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Results saved to persistent storage</li> </ul> <hr> <h2 id=test-scripts>ğŸ§ª Test Scripts<a class=headerlink href=#test-scripts title="Permanent link">&para;</a></h2> <p>We provide test scripts for all computing scenarios:</p> <h3 id=interactive-sessions_1>Interactive Sessions<a class=headerlink href=#interactive-sessions_1 title="Permanent link">&para;</a></h3> <ul> <li>Test scripts are provided inline in the examples above</li> </ul> <h3 id=batch-jobs>Batch Jobs<a class=headerlink href=#batch-jobs title="Permanent link">&para;</a></h3> <ul> <li><strong><a href=../scripts/computing-guide/test_cpu_job.sh>test_cpu_job.sh</a></strong> - Basic CPU job submission</li> <li><strong><a href=../scripts/computing-guide/test_basic_cpu.sh>test_basic_cpu.sh</a></strong> - Alternative CPU test</li> <li><strong><a href=../scripts/computing-guide/test_gpu_job.sh>test_gpu_job.sh</a></strong> - GPU allocation test</li> <li><strong><a href=../scripts/computing-guide/test_gpu_specific.sh>test_gpu_specific.sh</a></strong> - Specific GPU type selection (RTX 4090)</li> <li><strong><a href=../scripts/computing-guide/test_array_job.sh>test_array_job.sh</a></strong> - Array job for parameter sweeps</li> </ul> <p>To run the tests: <div class="language-bash highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># Test basic job submission</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>sbatch<span class=w> </span>test_cpu_job.sh
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a><span class=c1># Test GPU allocation</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a>sbatch<span class=w> </span>test_gpu_job.sh
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a><span class=c1># Test specific GPU request</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a>sbatch<span class=w> </span>test_gpu_specific.sh
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a>
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10 href=#__codelineno-24-10></a><span class=c1># Test array jobs (creates 6 tasks)</span>
</span><span id=__span-24-11><a id=__codelineno-24-11 name=__codelineno-24-11 href=#__codelineno-24-11></a>sbatch<span class=w> </span>test_array_job.sh
</span></code></pre></div></p> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../python-environments/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Overview"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Overview </div> </div> </a> <a href=../container-workflow/ class="md-footer__link md-footer__link--next" aria-label="Next: Container Workflow"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Container Workflow </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> &copy; 2025 <a href=https://rsl.ethz.ch target=_blank rel=noopener>Robotics Systems Lab</a>, ETH Zurich </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/leggedrobotics target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://rsl.ethz.ch target=_blank rel=noopener title=rsl.ethz.ch class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M351.9 280H161c2.9 64.5 17.2 123.9 37.5 167.4 11.4 24.5 23.7 41.8 35.1 52.4 11.2 10.5 18.9 12.2 22.9 12.2s11.7-1.7 22.9-12.2c11.4-10.6 23.7-28 35.1-52.4 20.3-43.5 34.6-102.9 37.5-167.4zm-191-48h190.9c-2.8-64.5-17.1-123.9-37.4-167.4-11.4-24.4-23.7-41.8-35.1-52.4C268.1 1.7 260.4 0 256.4 0s-11.7 1.7-22.9 12.2c-11.4 10.6-23.7 28-35.1 52.4-20.3 43.5-34.6 102.9-37.5 167.4m-48 0c3.5-85.6 25.6-165.1 57.9-217.3C78.7 47.3 10.9 131.2 1.5 232zM1.5 280c9.4 100.8 77.2 184.7 169.3 217.3-32.3-52.2-54.4-131.7-57.9-217.3zm398.4 0c-3.5 85.6-25.6 165.1-57.9 217.3 92.1-32.7 159.9-116.5 169.3-217.3zm111.4-48C501.9 131.2 434.1 47.3 342 14.7c32.3 52.2 54.4 131.7 57.9 217.3z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.path", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.tabs.link", "content.code.annotation", "content.code.copy", "content.action.edit", "content.action.view"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.f55a23d4.min.js></script> </body> </html>